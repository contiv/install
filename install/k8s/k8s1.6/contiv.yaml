---

apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: contiv-netplugin
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: contiv-netplugin
subjects:
- kind: ServiceAccount
  name: contiv-netplugin
  namespace: kube-system
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: contiv-netplugin
  namespace: kube-system
rules:
  - apiGroups:
      - ""
    resources:
      - pods
      - nodes
    verbs:
      - get
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: contiv-netplugin
  namespace: kube-system
---

apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: contiv-netmaster
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: contiv-netmaster
subjects:
- kind: ServiceAccount
  name: contiv-netmaster
  namespace: kube-system
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: contiv-netmaster
  namespace: kube-system
rules:
  - apiGroups:
    - ""
    - extensions
    resources:
      - pods
      - nodes
      - namespaces
      - networkpolicies
    verbs:
      - watch
      - list
      - update
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: contiv-netmaster
  namespace: kube-system

---

# This ConfigMap is used to configure a self-hosted Contiv installation.
# It can be used with an external cluster store(etcd or consul) or used
# with the etcd instance being installed as contiv-etcd
kind: ConfigMap
apiVersion: v1
metadata:
  name: contiv-config
  namespace: kube-system
data:
  # The location of your cluster store. This is set to the
  # avdertise-client value below from the contiv-etcd service.
  # Change it to an external etcd/consul instance if required.
  cluster_store: "etcd://__NETMASTER_IP__:6666"
  # The CNI network configuration to install on each node.
  cni_config: |-
    {
      "cniVersion": "0.1.0",
      "name": "contiv-net",
      "type": "contivk8s"
    }
  config: |-
    {
       "K8S_API_SERVER": "https://__NETMASTER_IP__:6443",
       "K8S_CA": "/var/run/secrets/kubernetes.io/serviceaccount/ca.crt",
       "K8S_KEY": "",
       "K8S_CERT": "",
       "K8S_TOKEN": ""
    }
---

# This manifest installs contiv-netplugin container, as well
# as the Contiv CNI plugins and network config on
# each master and worker node in a Kubernetes cluster.
kind: DaemonSet
apiVersion: extensions/v1beta1
metadata:
  name: contiv-netplugin
  namespace: kube-system
  labels:
    k8s-app: contiv-netplugin
spec:
  selector:
    matchLabels:
      k8s-app: contiv-netplugin
  template:
    metadata:
      labels:
        k8s-app: contiv-netplugin
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      hostNetwork: true
      hostPID: true
      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      serviceAccountName: contiv-netplugin
      containers:
        # Runs netplugin container on each Kubernetes node.  This
        # container programs network policy and routes on each
        # host.
        - name: contiv-netplugin
          image: contiv/netplugin:__CONTIV_VERSION__
          args:
            - -pkubernetes
            - -x
          env:
            - name: VLAN_IF
              value: __VLAN_IF__
            - name: VTEP_IP
              valueFrom:
                 fieldRef:
                    fieldPath: status.podIP
            - name: CONTIV_ETCD
              valueFrom:
                configMapKeyRef:
                  name: contiv-config
                  key: cluster_store
            - name: CONTIV_CNI_CONFIG
              valueFrom:
                configMapKeyRef:
                  name: contiv-config
                  key: cni_config
            - name: CONTIV_CONFIG
              valueFrom:
                configMapKeyRef:
                  name: contiv-config
                  key: config
          securityContext:
            privileged: true
          volumeMounts:
            - mountPath: /etc/openvswitch
              name: etc-openvswitch
              readOnly: false
            - mountPath: /lib/modules
              name: lib-modules
              readOnly: false
            - mountPath: /var/run
              name: var-run
              readOnly: false
            - mountPath: /var/contiv
              name: var-contiv
              readOnly: false
            - mountPath: /etc/kubernetes/pki
              name: etc-kubernetes-pki
              readOnly: false
            - mountPath: /etc/kubernetes/ssl
              name: etc-kubernetes-ssl
              readOnly: false
            - mountPath: /opt/cni/bin
              name: cni-bin-dir
              readOnly: false
            - mountPath: /etc/cni/net.d/
              name: etc-cni-dir
              readOnly: false
      volumes:
        # Used by contiv-netplugin
        - name: etc-openvswitch
          hostPath:
            path: /etc/openvswitch
        - name: lib-modules
          hostPath:
            path: /lib/modules
        - name: var-run
          hostPath:
            path: /var/run
        - name: var-contiv
          hostPath:
            path: /var/contiv
        - name: etc-kubernetes-pki
          hostPath:
            path: /etc/kubernetes/pki
        - name: etc-kubernetes-ssl
          hostPath:
            path: /etc/kubernetes/ssl
        # Used to install CNI.
        - name: cni-bin-dir
          hostPath:
            path: /opt/cni/bin
        - name: etc-cni-dir
          hostPath:
            path: /etc/cni/net.d/
---

# This manifest deploys the Contiv API Server on Kubernetes.
apiVersion: extensions/v1beta1
kind: ReplicaSet
metadata:
  name: contiv-netmaster
  namespace: kube-system
  labels:
    k8s-app: contiv-netmaster
spec:
  # The netmaster should have 1, 3, 5 nodes of which one is active at any given time.
  # More nodes are desired in a production environment for HA.
  replicas: 1
  template:
    metadata:
      name: contiv-netmaster
      namespace: kube-system
      labels:
        k8s-app: contiv-netmaster
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      # The netmaster must run in the host network namespace so that
      # it isn't governed by policy that would prevent it from working.
      hostNetwork: true
      hostPID: true
      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      serviceAccountName: contiv-netmaster
      containers:
        - name: contiv-netmaster
          image: contiv/netplugin:__CONTIV_VERSION__
          args:
            - -m
            - -pkubernetes
          env:
            - name: CONTIV_ETCD
              valueFrom:
                configMapKeyRef:
                  name: contiv-config
                  key: cluster_store
          securityContext:
            privileged: true
          volumeMounts:
            - mountPath: /etc/openvswitch
              name: etc-openvswitch
              readOnly: false
            - mountPath: /lib/modules
              name: lib-modules
              readOnly: false
            - mountPath: /var/run
              name: var-run
              readOnly: false
            - mountPath: /var/contiv
              name: var-contiv
              readOnly: false
            - mountPath: /etc/kubernetes/ssl
              name: etc-kubernetes-ssl
              readOnly: false
            - mountPath: /opt/cni/bin
              name: cni-bin-dir
              readOnly: false
      volumes:
        # Used by contiv-netmaster
        - name: etc-openvswitch
          hostPath:
            path: /etc/openvswitch
        - name: lib-modules
          hostPath:
            path: /lib/modules
        - name: var-run
          hostPath:
            path: /var/run
        - name: var-contiv
          hostPath:
            path: /var/contiv
        - name: etc-kubernetes-ssl
          hostPath:
            path: /etc/kubernetes/ssl
        - name: cni-bin-dir
          hostPath:
            path: /opt/cni/bin
---

# This manifest deploys the Contiv API Proxy Server on Kubernetes.
apiVersion: extensions/v1beta1
kind: ReplicaSet
metadata:
  name: contiv-api-proxy
  namespace: kube-system
  labels:
    k8s-app: contiv-api-proxy
spec:
  # The API proxy should have 1, 3, 5 nodes of which one is active at any given time.
  # More nodes are desired in a production environment for HA.
  replicas: 1
  template:
    metadata:
      name: contiv-api-proxy
      namespace: kube-system
      labels:
        k8s-app: contiv-api-proxy
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      # The API proxy must run in the host network namespace so that
      # it isn't governed by policy that would prevent it from working.
      hostNetwork: true
      hostPID: true
      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      serviceAccountName: contiv-netmaster
      containers:
        - name: contiv-api-proxy
          image: contiv/auth_proxy:__CONTIV_VERSION__
          args:
            - --tls-key-file=/var/contiv/auth_proxy_key.pem
            - --tls-certificate=/var/contiv/auth_proxy_cert.pem
            - --data-store-address=$(CONTIV_ETCD)
            - --netmaster-address=__NETMASTER_IP__:9999
          env:
            - name: NO_NETMASTER_STARTUP_CHECK
              value: "1"
            - name: CONTIV_ETCD
              valueFrom:
                configMapKeyRef:
                  name: contiv-config
                  key: cluster_store
          securityContext:
            privileged: false
          volumeMounts:
            - mountPath: /var/contiv
              name: var-contiv
              readOnly: false
      volumes:
        - name: var-contiv
          hostPath:
            path: /var/contiv

---

